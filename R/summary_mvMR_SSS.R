# https://github.com/verena-zuber/demo_AMD/blob/master/summary_mvMR_SSS.R
# MR-BMA has not been released as an R package. It is Copied from above
# and included here for comparison purposes only.
#
# 15th April 2019
# risk factor selection for multivariable MR based on Bayes Factors
# computation is based on summary data which speeds up computation
#
# functions
# summarymvMR_SSS: 		main function
# summary_stochastic_search: 	shotgun stochastic search
# create_environment: 		create new environment to search
# log_binom_gamma:		prior for model size
#

# Class
# mvMRInput:			input format for summarymvMR_SSS
# MR_SSS:			output format of summarymvMR_SSS


# now synced with manuscript and BF derivation
# input: object of class mvMRInput
# NOTE hash:: prevents clashes wit MendelianRandomization R package


library(combinat)
library(hash)







#
# class mv-mr input
#

# setClass("mvMRInput",
#          representation(betaX = "matrix",
#                         betaY = "matrix",
#                         betaXse = "matrix",
#                         betaYse = "matrix",
#                         exposure = "character",
#                         outcome = "character",
#                         snps = "character",
#                         effect_allele = "character",
#                         other_allele  = "character",
#                         eaf           = "numeric",
#                         correlation = "matrix")
# )








#
# output class
#


setClass("mvMR_SSS",
         representation(Exposure = "character",
                        Outcome = "character",
                        BMAve_Estimate = "numeric",
                        BestModel_Estimate = "numeric",
                        BestModel = "character",
                        tupel = "character",
                        pp="numeric",
                        pp_marginal="numeric",
                        betaX="matrix",
                        betaY="matrix")
)





#
# call the stochastic search function and prepare output
#



summarymvMR_SSS = function(object, kmin=1, kmax=20, max_iter=1000, sigma=0.5, prior_prob=0.5, print=FALSE){


  bX = object@betaX
  bY = object@betaY



  sigma_vec=rep(sigma, ncol(bX))

  sss=summary_stochastic_search(y=bY, x=bX, sigma_vec=sigma_vec, prior_prob=prior_prob, kmin=kmin, kmax=kmax, max_iter=max_iter, print=print)

  tupel_all = keys(sss$hashlogBF)
  log10BF = hash::values(sss$hashlogBF)
  log10prior = hash::values(sss$hashlogprior)
  theta_all = hash::values(sss$hashTheta)

  if(is.list(theta_all)){
    log10BF = unlist(log10BF)
    theta_all=t(matrix(unlist(theta_all), ncol = ncol(bX), byrow = TRUE))
  }

  #log_evidence = log10BF + log10prior
  log_evidence = unlist(log10BF) + unlist(log10prior)
  #best model
  best_model = tupel_all[which.max(log_evidence)]
  best_model_est = theta_all[,which.max(log_evidence)]
  #posterior for each model
  max_evidence = max(log_evidence)
  if(max_evidence>308){
    rescale_diff = max_evidence - 308
    log_evidence = log_evidence - (rescale_diff+1)
    max_evidence = 308
  }
  sum_calib = sum(10^(log_evidence-max_evidence)) * 10^max_evidence
  pp=10^log_evidence/sum_calib
  pp_mat=matrix(pp, ncol=length(pp), nrow=ncol(bX), byrow=TRUE)
  #model averaging causal effect
  BMA_estimate=rowSums(pp_mat * theta_all)
  #marginal inclusion
  index_mat = matrix(0, ncol=length(pp), nrow=ncol(bX))
  index=lapply(unlist(lapply(tupel_all, FUN=strsplit, split=","), recursive=FALSE), FUN=helper)
  for(i in 1:length(pp)){index_mat[unlist(index[i]),i] = 1}
  pp_marginal =rowSums(pp_mat * index_mat)
  bma_coef = BMA_estimate
  best_model_coef = best_model_est

  return(new("mvMR_SSS",
             Exposure = object@exposure,
             Outcome = object@outcome,
             BMAve_Estimate = bma_coef,
             BestModel_Estimate = best_model_coef,
             BestModel = best_model,
             tupel = tupel_all,
             pp=pp,
             pp_marginal = pp_marginal,
             betaX = bX,
             betaY= bY
  ))

}










#
# core stochastic search function
#



summary_stochastic_search = function(y,x,sigma_vec, prior_prob=0.5, kmin=1, kmax=20, max_iter=1000, print=FALSE){

  hashlogprior=hash()
  hashlogBF=hash()
  hashTheta=hash()
  n_SNPs = nrow(x)
  n_RF = ncol(x)
  XtX = t(x) %*% x		# dim  d=10  x d=10
  XtY = t(x) %*% y		# dim  d=10  x 1
  YtY = t(y) %*% y

  #deterministic part
  for (i in 1:kmin){
    #create all combinations of i variables
    comb = matrix(combn(1:ncol(x), i),nrow=i)
    new_neighbourhood = lapply(seq_len(ncol(comb)), function(i) comb[,i])
    #compute log prior
    configlogprior = lapply(new_neighbourhood, FUN = log_binom_gamma, n_RF, prior_prob)
    #compute logBF / theta
    configlogBF=lapply(new_neighbourhood, FUN = logBF_summary, XtY=XtY,XtX=XtX,YtY=YtY, sigma_vec=sigma_vec, n=n_SNPs)
    configTheta=lapply(new_neighbourhood, FUN = beta_summary, XtY=XtY,XtX=XtX,sigma_vec=sigma_vec)
    #compute the log evidence
    #save as hash table with key=tupel - value (logBF or theta)
    if(i>1){tupel=apply(comb, MARGIN=2, FUN=paste, collapse=",") }
    else{tupel=new_neighbourhood}

    if(i==ncol(x)){
      hashlogprior[tupel] = configlogprior[[1]]
      hashlogBF[tupel] = configlogBF[[1]]
      hashTheta[tupel] = configTheta[[1]]
    }
    else{
      hashlogprior[tupel] = configlogprior
      hashlogBF[tupel] = configlogBF
      hashTheta[tupel] = configTheta
    }
  }



  #stochastic part
  iter = 1
  #only run stochastic search if kmax > kmin
  if(kmax > kmin){
    while (iter< max_iter){
      #print(paste("sss run: ", iter))
      #draw a random configuration with weights according to BF from the last set of tupel
      log_evidence = unlist(configlogBF) + unlist(configlogprior)
      max_evidence = max(log_evidence)
      if(max_evidence>308){
        rescale_diff = max_evidence - 308
        log_evidence = log_evidence - (rescale_diff+1)
        max_evidence = 308
      }
      sum_calib = sum(10^(log_evidence-max_evidence)) * 10^max_evidence
      evidence = 10^(log_evidence)
      random_nr=sample(1:length(evidence), size=1, prob = evidence/sum_calib)
      random_config=new_neighbourhood[[random_nr]]
      if(print==TRUE){print(c(iter, random_config))}
      #create new neighbourhood
      new_neighbourhood = create_environment(random_config,ncol(x), kmin=kmin, kmax = kmax)
      tupel=lapply(new_neighbourhood, paste, collapse=",")
      #check which ones we visited already and query their logBF
      visited_already=has.key(tupel, hashlogBF)
      tupel_visited2=tupel[visited_already]
      #we need the correct keys - values order
      tupel_visited=keys(hashlogBF[tupel_visited2])
      logBF_visited=hash::values(hashlogBF[tupel_visited2])
      logprior_visited=hash::values(hashlogprior[tupel_visited2])
      if(sum(visited_already)==length(visited_already)){
        configlogBF=logBF_visited
        configlogprior=logprior_visited
        test2=unlist(lapply(tupel_visited, FUN=strsplit, split=","), recursive=FALSE)
        new_neighbourhood = lapply(test2,FUN=helper)
      }
      else{
        #compute log prior for the neighboorhood
        configlogprior_new = lapply(new_neighbourhood[!visited_already], FUN = log_binom_gamma, n_RF, prior_prob)
        #compute logBF / theta for the neighboorhood
        configlogBF_new=lapply(new_neighbourhood[!visited_already],  FUN = logBF_summary, XtY=XtY,XtX=XtX,YtY=YtY, sigma_vec=sigma_vec, n=n_SNPs)
        configTheta_new=lapply(new_neighbourhood[!visited_already],   FUN = beta_summary, XtY=XtY,XtX=XtX,sigma_vec=sigma_vec)
        #save as hash table with key=tupel - value (logBF or theta)
        tupel_insert=lapply(new_neighbourhood[!visited_already], paste, collapse=",")
        hashlogprior[tupel_insert] = configlogprior_new
        hashlogBF[tupel_insert] = configlogBF_new
        hashTheta[tupel_insert] = configTheta_new
        #prepare new random draw
        #tupel=merge tupel_visited and tupel_insert
        c_tupel = c(tupel_visited, tupel_insert)
        test2=unlist(lapply(c_tupel, FUN=strsplit, split=","), recursive=FALSE)
        new_neighbourhood = lapply(test2,FUN=helper)
        #configlogBF = merge logBF_visited and configlogBF_new
        configlogBF = c(logBF_visited, configlogBF_new)
        configlogprior = c(logprior_visited, configlogprior_new)
        #and move on with the new neighbourhood and logBF as starting point for the random draw
      }
      iter = iter +1
    }
  }

  return(list(hashlogBF=hashlogBF, hashTheta=hashTheta, hashlogprior=hashlogprior))

}













#
# function that creates a new envirnoment given a starting configuraiton current config,
# the size of the design matrix m,
# and the minimum (kmin=1) and maximum size (kmax=20) of models considered
#



create_environment=function(current_config, m, kmin=1, kmax=20){

  actual_kmax=min(kmax,m)
  current_size=length(current_config)
  all_members = 1:m
  possible_new_members = setdiff(all_members,current_config)

  new_neighbourhood = list()

  if(current_size == kmin){

    #swap move new_size = current_size
    for(i in 1:current_size){
      j=length(new_neighbourhood)
      loop_config=current_config[-i]
      for(k in 1:length(possible_new_members)){
        new_neighbourhood[[j+k]] = sort(c(loop_config, possible_new_members[k]))
      }
    }

    #add move new_size = current_size + 1
    j=length(new_neighbourhood)
    for(i in 1:length(possible_new_members)){
      new_neighbourhood[[j+i]] = sort(c(current_config, possible_new_members[i]))
    }

    j=length(new_neighbourhood)
    new_neighbourhood[[j+1]] = current_config

  }

  else if(current_size == kmax){

    #delete move new_size = current_size - 1
    for(i in 1:current_size){
      new_neighbourhood[[i]] = current_config[-i]
    }

    #swap move new_size = current_size
    for(i in 1:current_size){
      j=length(new_neighbourhood)
      loop_config=current_config[-i]
      for(k in 1:length(possible_new_members)){
        new_neighbourhood[[j+k]] = sort(c(loop_config, possible_new_members[k]))
      }
    }

    j=length(new_neighbourhood)
    new_neighbourhood[[j+1]] = current_config

  }

  else{
    #delete move new_size = current_size - 1
    for(i in 1:current_size){
      new_neighbourhood[[i]] = current_config[-i]
    }

    #swap move new_size = current_size
    for(i in 1:current_size){
      j=length(new_neighbourhood)
      loop_config=current_config[-i]
      for(k in 1:length(possible_new_members)){
        new_neighbourhood[[j+k]] = sort(c(loop_config, possible_new_members[k]))
      }
    }

    #add move new_size = current_size + 1
    j=length(new_neighbourhood)
    for(i in 1:length(possible_new_members)){
      new_neighbourhood[[j+i]] = sort(c(current_config, possible_new_members[i]))
    }

    j=length(new_neighbourhood)
    new_neighbourhood[[j+1]] = current_config


  }

  return(new_neighbourhood)

}




#
# function to compute a binomial prior with prior prob
#


log_binom_gamma = function(gamma, n_x, prior_prob){

  n_model_size = length(gamma)
  log_prior = log10(prior_prob^n_model_size * (1-prior_prob)^(n_x-n_model_size))

  return(log_prior)

}







#
# make table: report the best individual models
#


#input
#BMA_output object of class mvMR_SSS
#prior_sigma needs to be specified as in main function
#top = 10 how many top models to be reported?
#write.out = FALSE write out table as csv file
#csv.file.name = "best_model_out"



sss.report.best.model = function(BMA_output, prior_sigma=0.5, top = 10, digits = 3, write.out = TRUE, csv.file.name="best_model_out"){


  if(class(BMA_output)[1] !="mvMR_SSS"){
    message("Input needs to be of class mvMR_SSS")
    break
  }

  pp=BMA_output@pp
  models=BMA_output@tupel
  betaX=BMA_output@betaX
  betaY=BMA_output@betaY
  rf=BMA_output@Exposure
  sort_pp_model_object=sort.int(pp, index.return=TRUE, decreasing=TRUE)
  grep_rf=models[sort_pp_model_object$ix][1:top]


  rf_top = list()
  tupel_top = list()
  for(i in 1:top){
    tupel_top[[i]] =as.numeric(unlist(strsplit(grep_rf[i], ",")))
    rf_top[i]=paste(rf[as.numeric(unlist(strsplit(grep_rf[i], ",")))],  collapse=",")
  }

  theta_top = list()
  Theta=lapply(tupel_top, FUN = beta_gamma, y=as.matrix(betaY),x=as.matrix(betaX), sigma_vec=rep(0.5, ncol(as.matrix(betaX))))

  for(i in 1:top){
    Theta_iter = Theta[[i]]
    Theta_iter[Theta_iter!=0]
    theta_top[[i]]= paste(round(Theta_iter[Theta_iter!=0],digits=digits),  collapse=",")
  }

  best_models_out=cbind(rf_top, round(pp[sort_pp_model_object$ix][1:top],digits=digits), theta_top)
  colnames(best_models_out) = c("rf combination", "posterior probability", "causal estimate")


  if(write.out == TRUE){write.csv(best_models_out, file=csv.file.name)}

  return(best_models_out)

}





#
# make table: report the model-averaged results (MR-BMA)
#


#input
#BMA_output object of class mvMR_SSS
#top = 10 how many top models to be reported?
#write.out = FALSE write out table as csv file
#csv.file.name = "mr_bma_out"



sss.report.mr.bma = function(BMA_output,  top = 10, digits = 3, write.out = TRUE, csv.file.name="mr_bma_out"){

  if(class(BMA_output)[1] !="mvMR_SSS"){
    message("Input needs to be of class mvMR_SSS")
    break
  }

  pp_marginal = BMA_output@pp_marginal
  bma=BMA_output@BMAve_Estimate
  rf=BMA_output@Exposure
  sort_pp_object=sort.int(pp_marginal, index.return=TRUE, decreasing=TRUE)
  marginal_out=cbind(rf[sort_pp_object$ix][1:top], round(pp_marginal[sort_pp_object$ix][1:top],digits=digits), round(bma[sort_pp_object$ix][1:top],digits=digits) )
  colnames(marginal_out)=c("rf", "marginal inclusion", "average effect")

  if(write.out == TRUE){write.csv(marginal_out, file=csv.file.name)}

  return(marginal_out)

}














helper = function(x){
  as.numeric(x[, drop =  F])
}


#
# 15th April 2019
# risk factor selection for multivariable MR based on Bayes Factors
# computation is based on summary data which speeds up computation
#
# functions
# summary_mvMR_BF: 	exhaustive evaluation of all combinations of risk factors
# logBF_summary: 	compute log10 Bayes factor for indicator on summary data
# beta_summary: 	compute causal estimate for indicator on summary data
# cooksD: 		Cooks distance
# beta_est, beta_gamma: compute causal estimate on data matrix
# logBF, logBF_gamma:	compute log10 Bayes factor for indicator on data matrix
#

# Class
# mvMRInput:		input format for summary_mvMR_BF
# MRBF:			output format of summary_mvMR_BF



library(combinat)





#
# class mv-mr input
#





setClass("MRBF",
         representation(Exposure = "character",
                        Outcome = "character",
                        BMAve_Estimate = "numeric",
                        BestModel_Estimate = "numeric",
                        BestModel = "character",
                        tupel = "character",
                        pp="numeric",
                        pp_marginal="numeric",
                        betaX="matrix",
                        betaY="matrix")
)









#
# summary_mvMR_BF
#

summary_mvMR_BF = function(object, sigma=0.5, prior_prob=0.5){


  #bX = object@betaX
  #bY = object@betaY
  n_SNPs = nrow(bX)
  n_RF = ncol(bX)
  XtX = t(bX) %*% bX		# dim  d=10  x d=10
  XtY = t(bX) %*% bY		# dim  d=10  x 1
  YtY = t(bY) %*% bY

  tupel_all = matrix(character(0),0,0)
  logBF_all = matrix(numeric(0), 0,0)
  logprior_all = matrix(numeric(0), 0,0)
  theta_all = matrix(numeric(0), (ncol(bX)),0)
  sigma_vec=rep(sigma, ncol(bX))

  #for (i in 1:ncol(bX)){
  for (i in 1:5){

    combi=matrix(combn(1:ncol(bX), i),nrow=i)
    tupel=apply(combi, 2, paste, collapse=",")
    tupel_all = c(tupel_all, tupel)
    logBF = apply(combi, MARGIN=2, FUN = logBF_summary, XtY=XtY,XtX=XtX,YtY=YtY, sigma_vec=sigma_vec, n=n_SNPs)
    logBF_all = c(logBF_all,logBF)
    log_prior=log10(prior_prob^i*(1-prior_prob)^(n_RF-i))
    logprior_vec = rep(log_prior,length(logBF))
    logprior_all = c(logprior_all,logprior_vec)
    theta_est = apply(combi, MARGIN=2, FUN = beta_summary, XtY=XtY,XtX=XtX,sigma_vec=sigma_vec)
    theta_all = cbind(theta_all,theta_est)
  }

  log_evidence = logBF_all + logprior_all

  #best model
  best_model = tupel_all[which.max(log_evidence)]
  best_model_est = theta_all[,which.max(log_evidence)]
  #posterior for each model
  max_evidence = max(log_evidence)
  if(max_evidence>308){
    rescale_diff = max_evidence - 308
    log_evidence = log_evidence - rescale_diff
    max_evidence = 308
  }
  sum_calib = sum(10^(log_evidence-max_evidence)) * 10^max_evidence
  pp=10^log_evidence/sum_calib
  pp_mat=matrix(pp, ncol=length(pp), nrow=ncol(bX), byrow=TRUE)
  #model averaging causal effect
  BMA_estimate=rowSums(pp_mat * theta_all)
  #marginal inclusion
  index_mat = matrix(0, ncol=length(pp), nrow=ncol(bX))
  index=lapply(unlist(lapply(tupel_all, FUN=strsplit, split=","), recursive=FALSE), FUN=helper)
  for(i in 1:length(pp)){index_mat[unlist(index[i]),i] = 1}
  pp_marginal =rowSums(pp_mat * index_mat)
  bma_coef = BMA_estimate
  best_model_coef = best_model_est


  return(new("MRBF",
             Exposure = object@exposure,
             Outcome = object@outcome,
             BMAve_Estimate = bma_coef,
             BestModel_Estimate = best_model_coef,
             BestModel = best_model,
             tupel = tupel_all,
             pp=pp,
             pp_marginal = pp_marginal,
             betaX = bX,
             betaY= bY

  ))

}















#
# compute the logBF for a set of risk factors given gamma (indicator vector)
#

logBF_summary = function(XtY,XtX,YtY,sigma_vec, gamma, n){

  #print(gamma)
  XtY_g = XtY[gamma]
  XtX_g = XtX[gamma, gamma]
  sigma_g = sigma_vec[gamma]

  invnu=diag(sigma_g^-2, ncol=length(gamma))
  invOmega=(invnu + XtX_g)
  B=solve(invOmega)%*%XtY_g
  logBF=(-0.5*log10(det(invOmega))  - log10(prod(sigma_g)) - (n/2) *(log10(YtY - t(B)%*%invOmega%*%B)-log10(YtY)))

  return(logBF)

}


#
# compute the causal estimates for a set of risk factors given gamma (indicator vector)
#


beta_summary = function(XtY=XtY,XtX=XtX,sigma_vec, gamma){

  XtY_g = XtY[gamma]
  XtX_g = XtX[gamma, gamma]
  sigma_g = sigma_vec[gamma]

  invnu=diag(sigma_g^-2, ncol=length(gamma))
  theta_out = rep(0, nrow(XtY))
  invOmega=(invnu + XtX_g)
  B=solve(invOmega)%*%XtY_g
  theta_out[gamma] = B

  return(theta_out)
}








#
# Cooks distance
#


# input: y = betaY, x = betaX, sigma_vec = prior variance
# output: cooksD = cooks Distance, cooksD_thresh = suggested threshold based on a F distribution with df1=d,df2=k-d


cooksD = function(y,x,sigma_vec){
  k=length(y)
  d=ncol(x)
  x_mat=x
  H_fm = x_mat %*% solve(t(x_mat) %*% x_mat + sigma_vec^{-2} ) %*% t(x_mat)
  h_i = diag(H_fm)
  e = y-(H_fm%*%y)
  s_sq = c(1/(k-d) * t(e) %*% e)
  cooksD = e^2/(s_sq * d) * (h_i/(1-h_i)^2 )
  thresh=qf(0.5,df1=d,df2=k-d)
  return(list(cooksD=cooksD,cooksD_thresh=thresh))
}










#
# further functions to compute beta based on data matrix
#

# compute the logBF for a set of risk factors

#y outcome
#x predictors (genetic associations with risk factors)
#xmat designmatrix
#sigma_vec vector or prior variances

logBF = function(y,x,sigma_vec){

  k=length(y)
  xmat=x
  invnu=diag(sigma_vec^-2, ncol=ncol(xmat))
  invOmega=(invnu + t(xmat)%*% xmat)
  #invOmega0=k
  B=solve(invOmega)%*%t(xmat)%*%y
  logBF=(-0.5*log10(det(invOmega)) - log10(prod(sigma_vec)) - (k/2) *(log10(t(y)%*% y - t(B)%*%invOmega%*%B)-log10(t(y)%*%y)))
  return(logBF)
}



logBF_gamma = function(y,x,sigma_vec, gamma){

  k=length(y)
  sigma_g = sigma_vec[gamma]
  xmat=x[,gamma]
  invnu=diag(sigma_g^-2, ncol=length(gamma))
  invOmega=(invnu + t(xmat)%*% xmat)
  B=solve(invOmega)%*%t(xmat)%*%y
  logBF=(-0.5*log10(det(invOmega))  - log10(prod(sigma_g)) - (k/2) *(log10(t(y)%*% y - t(B)%*%invOmega%*%B)-log10(t(y)%*%y)))

  return(logBF)

}




# compute the causal estimates for a set of risk factors given gamma (indicator vector)

beta_gamma = function(y,x,sigma_vec, gamma){

  k=length(y)
  sigma_g = sigma_vec[gamma]
  xmat=x[,gamma]
  invnu=diag(sigma_g^-2, ncol=length(gamma))
  theta_out = rep(0, ncol(x))
  invOmega=(invnu + t(xmat)%*% xmat)
  B=solve(invOmega)%*%t(xmat)%*%y
  theta_out[gamma] = B

  return(theta_out)
}


# compute the causal estimates for a set of risk factors

beta_est = function(y,x,sigma_vec, intercept){

  k=length(y)
  xmat=x
  invnu=diag(sigma_vec^-2, ncol=ncol(x))
  theta_out = rep(0, ncol(x))
  invOmega=(invnu + t(xmat)%*% xmat)
  B=solve(invOmega)%*%t(xmat)%*%y
  theta_out = B

  return(theta_out)
}












#
# make table: report the best individual models
#


#input
#BMA_output object of class MRBF
#prior_sigma needs to be specified as in main function
#top = 10 how many top models to be reported?
#write.out = FALSE write out table as csv file
#csv.file.name = "best_model_out"



report.best.model = function(BMA_output, prior_sigma=0.5, top = 10, digits = 3, write.out = TRUE, csv.file.name="best_model_out"){


  if(class(BMA_output)[1] !="MRBF"){
    message("Input needs to be of class MRBF")
    break
  }

  pp=BMA_output@pp
  models=BMA_output@tupel
  betaX=BMA_output@betaX
  betaY=BMA_output@betaY
  rf=BMA_output@Exposure
  sort_pp_model_object=sort.int(pp, index.return=TRUE, decreasing=TRUE)
  grep_rf=models[sort_pp_model_object$ix][1:top]

  rf_top = list()
  tupel_top = list()
  for(i in 1:top){
    tupel_top[[i]] =as.numeric(unlist(strsplit(grep_rf[i], ",")))
    rf_top[i]=paste(rf[as.numeric(unlist(strsplit(grep_rf[i], ",")))],  collapse=",")
  }

  theta_top = list()
  Theta=lapply(tupel_top, FUN = beta_gamma, y=as.matrix(betaY),x=as.matrix(betaX), sigma_vec=rep(0.5, ncol(as.matrix(betaX))))

  for(i in 1:top){
    Theta_iter = Theta[[i]]
    Theta_iter[Theta_iter!=0]
    theta_top[[i]]= paste(round(Theta_iter[Theta_iter!=0],digits=digits),  collapse=",")
  }

  best_models_out=cbind(rf_top, round(pp[sort_pp_model_object$ix][1:top],digits=digits), theta_top)
  colnames(best_models_out) = c("rf combination", "posterior probability", "causal estimate")


  if(write.out == TRUE){write.csv(best_models_out, file=csv.file.name)}

  return(best_models_out)

}





#
# make table: report the model-averaged results (MR-BMA)
#


#input
#BMA_output object of class MRBF
#top = 10 how many top models to be reported?
#write.out = FALSE write out table as csv file
#csv.file.name = "mr_bma_out"



report.mr.bma = function(BMA_output,  top = 10, digits = 3, write.out = TRUE, csv.file.name="mr_bma_out"){

  if(class(BMA_output)[1] !="MRBF"){
    message("Input needs to be of class MRBF")
    break
  }

  pp_marginal = BMA_output@pp_marginal
  bma=BMA_output@BMAve_Estimate
  rf=BMA_output@Exposure
  sort_pp_object=sort.int(pp_marginal, index.return=TRUE, decreasing=TRUE)
  marginal_out=cbind(rf[sort_pp_object$ix][1:top], round(pp_marginal[sort_pp_object$ix][1:top],digits=digits), round(bma[sort_pp_object$ix][1:top],digits=digits) )
  colnames(marginal_out)=c("rf", "marginal inclusion", "average effect")

  if(write.out == TRUE){write.csv(marginal_out, file=csv.file.name)}

  return(marginal_out)

}




















helper = function(x){
  as.numeric(x[, drop =  F])
}





